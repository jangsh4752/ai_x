{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8ec294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:86% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.output {font-size:15pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:15px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:86% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.output {font-size:15pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:15px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480418b5",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch2. LLM활용의 기본 개념(Ollama)</span>\n",
    "\n",
    "# 1. LLM을 활용하여 답변 생성하기\n",
    "\n",
    "## 1) Ollama 이용한 로컬 LLM 이용\n",
    "- 성능은 GPT, Claude 같은 모델보다는 떨어짐 / 개념 설명을 의해 open source 모델 사용\n",
    "\n",
    "### ⓐ ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "- ollama pull deepseek-r1:1.5b(window키 + R -> powershell 창 실행) -> ollama run deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ec3d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nThe capital of Korea is Washington D.C.', additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-06-26T01:34:15.7490737Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3835013200, 'load_duration': 2800984400, 'prompt_eval_count': 10, 'prompt_eval_duration': 250026200, 'eval_count': 14, 'eval_duration': 779339900, 'model_name': 'deepseek-r1:1.5b'}, id='run--5aadb040-df0d-486c-9e70-0811d4340fc5-0', usage_metadata={'input_tokens': 10, 'output_tokens': 14, 'total_tokens': 24})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result # 추론모델<think>~<think>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe25235",
   "metadata": {},
   "source": [
    "### ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "- ollama pull llama3.2:1b -> ollama run llama3.2:1b\n",
    "- llama : 공식적으로 한글지원 안됨(llama3.1:405b 한글지원 가능->llama3.3:70b)\n",
    "- exaone : 공식적으로 한글 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d85ebce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of South Korea is Seoul. However, it's worth noting that there are also two other cities that serve as major capitals: Busan to the west and Daejeon to the east. But Seoul is the most well-known and widely used term for the country's capital.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-26T01:34:22.9585673Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7138847300, 'load_duration': 2804705700, 'prompt_eval_count': 32, 'prompt_eval_duration': 630799000, 'eval_count': 59, 'eval_duration': 3702832100, 'model_name': 'llama3.2:1b'}, id='run--3c01e4a6-1d1e-4d2b-8bd9-3c5cebfa4635-0', usage_metadata={'input_tokens': 32, 'output_tokens': 59, 'total_tokens': 91})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773eb3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The capital of South Korea is Seoul. However, it's worth noting that there are also two other cities that serve as major capitals: Busan to the west and Daejeon to the east. But Seoul is the most well-known and widely used term for the country's capital.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ebe1517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국의 수도는 Seoul입니다.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-26T01:34:23.7788576Z', 'done': True, 'done_reason': 'stop', 'total_duration': 758233100, 'load_duration': 27544700, 'prompt_eval_count': 32, 'prompt_eval_duration': 262909600, 'eval_count': 8, 'eval_duration': 467264600, 'model_name': 'llama3.2:1b'}, id='run--ff8867cb-eb4c-448c-a917-2fca5c820b2d-0', usage_metadata={'input_tokens': 32, 'output_tokens': 8, 'total_tokens': 40})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"한국 수도는 어디예요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92df044",
   "metadata": {},
   "source": [
    "## 2) Openai 활용\n",
    "- pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6f4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# result = llm.invoke(\"What is the capital of Korea?\")\n",
    "# result - 에러 이유 : 환경변수(OPENAI_API_KEY) 부재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d15c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경 변수 가져오기\n",
    "from dotenv import load_dotenv\n",
    "# import os\n",
    "load_dotenv()\n",
    "# os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f810bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩에서 OPENAI_API_KEY 읽어오기(.env 못씀)\n",
    "# 보안키 추가 후\n",
    "# from google.colab import userdata\n",
    "# userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f36a193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='대한민국의 수도는 서울입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 19, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-BmVnLTUUwQ0Bo23gi7vEqQXVVVrz7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4bb24a12-87e9-425d-9490-774e95082dbc-0', usage_metadata={'input_tokens': 19, 'output_tokens': 8, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\",\n",
    "#                  openai_api_key=os.genenv('OPENAI_API_KEY'),\n",
    "                )\n",
    "llm.invoke(\"What is the capital of Korea? Answer me in Korean.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a1e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델의 키가 OPENAI_API_KEY는 아님\n",
    "# Claude -> Anthropic\n",
    "# Azure, upstage, Bedrock : 에러 메세지 참조하여 환경변수 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "072d93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import AzureOpenAI\n",
    "# llm = AzureOpenAI(model=\"gpt-4.1-nano\")\n",
    "# 에러를 내면 OPENAI_API_VERSION 환경변수가 필요하다는 메세지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7501334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "# llm.invoke(\"What is the capital of Korea?\")\n",
    "# 에러 메세지를 봐도 환경변수 이름을 알 수 없음(claude만 해당) -> ChatAnthropic을 google에 검색 후 langchain docs에서 명시한\n",
    "# ANTHROPIC_API_KEY 이름의 환경 변수 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835eb554",
   "metadata": {},
   "source": [
    "# 2. 렝체인 스타일로 프롬프트 작성하기\n",
    "- 프롬프트 : llm호출시 쓰는 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e11ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "# llm.invoke(0)\n",
    "# 프롬프트 타입 : 스트링, PromptValue, BaseMessage리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2396b",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    "- PromptTemplate을 사용하여 변수가 포함된 템플릿 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c5dacc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of South Korea is Seoul. However, it's worth noting that North Korea also claims Seoul as its capital, and the two countries have a complex relationship due to their separation since the Korean War in 1950.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-26T01:34:30.0347415Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3370940000, 'load_duration': 21419300, 'prompt_eval_count': 31, 'prompt_eval_duration': 297574900, 'eval_count': 46, 'eval_duration': 3051380000, 'model_name': 'llama3.2:1b'}, id='run--96062242-1741-4d7c-84a7-178e334462d1-0', usage_metadata={'input_tokens': 31, 'output_tokens': 46, 'total_tokens': 77})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}\", # {}안의 값을 새로운 값으로 대입 가능\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "prompt = prompt_template.invoke({\"country\":\"Korea\"})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae37d3a",
   "metadata": {},
   "source": [
    "## 2) 메세지 기반 프롬프트 작성\n",
    "- BaseMessage리스트\n",
    "- BaseMessage 상속받은 클래스 : AIMessage, HumanMessage, SystemMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bd6aef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-26T01:34:31.9563277Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1867648500, 'load_duration': 22598500, 'prompt_eval_count': 86, 'prompt_eval_duration': 1434158700, 'eval_count': 8, 'eval_duration': 408795400, 'model_name': 'llama3.2:1b'}, id='run--9eb9b497-1332-42a2-a309-d1c83799b567-0', usage_metadata={'input_tokens': 86, 'output_tokens': 8, 'total_tokens': 94})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"),\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"),\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),\n",
    "    HumanMessage(content=\"What is the capital of Korea?\"),\n",
    "    AIMessage(content=\"The capital of Korea is Seoul.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\")\n",
    "]\n",
    "llm.invoke(message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7321e0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Italy?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of Italy is Rome.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Korea?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of Korea is Seoul.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# BaseMessage list로 하면 렝체인화X, ChatPromptTemplate X\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"),\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"),\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),\n",
    "    HumanMessage(content=\"What is the capital of Korea?\"),\n",
    "    AIMessage(content=\"The capital of Korea is Seoul.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\")\n",
    "]\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chatPromptTemplate = ChatPromptTemplate.from_messages(message_list)\n",
    "prompt = chatPromptTemplate.invoke({'country':'Korea'})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24912a",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate 사용\n",
    "- BaseMessage 리스트 -> 튜플 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3778fac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요?한국\n",
      "프롬프트 :  messages=[SystemMessage(content='You are a helpful assistant!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of 한국?', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of South Korea is Seoul.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 BaseMessage를 수정\n",
    "chatPromptTemplate = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant!\"),\n",
    "    (\"human\", \"What is the capital of {country}?\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요?\")\n",
    "prompt = chatPromptTemplate.invoke({'country':country})\n",
    "print(\"프롬프트 : \",prompt)\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aeabe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요?한국\n",
      "프롬프트 :  messages=[SystemMessage(content='당신은 대한민국 전문 도우미야!', additional_kwargs={}, response_metadata={}), HumanMessage(content='한국의 수도가 어디예요?', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국의 수도는 서울입니다.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-26T01:34:42.0173218Z', 'done': True, 'done_reason': 'stop', 'total_duration': 980916900, 'load_duration': 28104800, 'prompt_eval_count': 43, 'prompt_eval_duration': 536441900, 'eval_count': 8, 'eval_duration': 415738500, 'model_name': 'llama3.2:1b'}, id='run--c7eca53e-cf89-4414-b82c-bd6368aec9d4-0', usage_metadata={'input_tokens': 43, 'output_tokens': 8, 'total_tokens': 51})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatPromptTemplate = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 대한민국 전문 도우미야!\"),\n",
    "    (\"human\", \"{country}의 수도가 어디예요?\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요?\")\n",
    "prompt = chatPromptTemplate.invoke({'country':country})\n",
    "print(\"프롬프트 : \",prompt)\n",
    "result = llm.invoke(prompt)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9a52d",
   "metadata": {},
   "source": [
    "# 3. 답변 형식을 컨트롤하기\n",
    "- invoke 실행결과는 AIMessage() -> String이나 json, 객체 : outputParser 이용\n",
    "\n",
    "## 1) 문자열 출력 파서 이용\n",
    "- StrOutputParser를 사용하여 LLM 출력(AIMessage)을 단순 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "563cf5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프롬프트 :  text='What is the capital of Korea. Return the name of the city only'\n",
      "llm 결과 :  <class 'langchain_core.messages.ai.AIMessage'> content='Seoul' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-26T01:34:42.7053088Z', 'done': True, 'done_reason': 'stop', 'total_duration': 637234900, 'load_duration': 25360600, 'prompt_eval_count': 39, 'prompt_eval_duration': 480671100, 'eval_count': 3, 'eval_duration': 130366300, 'model_name': 'llama3.2:1b'} id='run--ac791771-34a0-420b-822c-921dc14ddf3b-0' usage_metadata={'input_tokens': 39, 'output_tokens': 3, 'total_tokens': 42}\n",
      "파서 결과 :  Seoul\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Return the name of the city only\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "# 프롬프트 템플릿에 값 주입\n",
    "prompt = prompt_template.invoke({\"country\" : \"Korea\"})\n",
    "print(\"프롬프트 : \",prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print(\"llm 결과 : \", type(result), result)\n",
    "# 문자열 출력 파서를 이용하여 llm응답을 단순 문자열 변환\n",
    "output_parser = StrOutputParser()\n",
    "print('파서 결과 : ', output_parser.invoke(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04df4b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9489969d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate(변수설정) => ChatPromptTemplate(변수설정, system과 모범답안 지정)\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant with expertise in South Korea.\"),\n",
    "    (\"human\", \"What is the capital of {country}? Return the name if the city only.\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(chat_prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592cce1a",
   "metadata": {},
   "source": [
    "## 2) Json 출력 파서 이용\n",
    "- json()으로 응답하기를 원하지만, 우선 어떤 형식으로 반환되는지 확인\n",
    "- {\"name\":\"홍\", \"age\":22}(json) / {\"name\":\"홍\", \"age\":22}(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2b9323e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.StringPromptValue'> text='Give following information about Korea\\n    - Capital\\n    - Population\\n    - Language\\n    - Currency\\n    return it is JSON format and return the JSON dictionary only'\n",
      "<class 'langchain_core.prompt_values.StringPromptValue'> content='```\\n{\\n    \"capital\": \"Seoul\",\\n    \"population\": 51000000,\\n    \"language\": \"Korean\",\\n    \"currency\": \"Won\"\\n}\\n```' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-26T01:34:47.3311716Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3392159200, 'load_duration': 26315900, 'prompt_eval_count': 59, 'prompt_eval_duration': 915936000, 'eval_count': 38, 'eval_duration': 2448516500, 'model_name': 'llama3.2:1b'} id='run--1ad11046-7961-4547-9adb-87068bbb8ce0-0' usage_metadata={'input_tokens': 59, 'output_tokens': 38, 'total_tokens': 97}\n",
      "<class 'dict'> {'capital': 'Seoul', 'population': 51000000, 'language': 'Korean', 'currency': 'Won'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables = [\"country\"]    \n",
    ")\n",
    "prompt = country_detail_prompt.invoke({\"country\":\"Korea\"})\n",
    "print(type(prompt), prompt)\n",
    "# Json output 파서\n",
    "output_parser = JsonOutputParser()\n",
    "ai_message = llm.invoke(prompt)\n",
    "print(type(prompt), ai_message)\n",
    "json_result = output_parser.invoke(ai_message)\n",
    "print(type(json_result), json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7c5f610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Seoul',\n",
       " 'population': 50914541,\n",
       " 'language': 'Korean',\n",
       " 'currency': 'South Korean won'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables = [\"country\"]    \n",
    ")\n",
    "output_parser = JsonOutputParser()\n",
    "info = output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\n",
    "                                                                     \"Korea\"})))\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43509438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe226b69",
   "metadata": {},
   "source": [
    "## 3) 구조화된 출력 사용\n",
    "- Pydantic 모델을 사용하여 LLM 출력을 구조화된 형식으로 받기(JsonParser보다 훨씬 안정적)\n",
    "- Pydantic : 데이터 유효성 검사, 설정관리를 간편하게 해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8e8e509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x0000025D2520E530>\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self, id, name, is_active=True):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.is_active = is_active\n",
    "user = User(\"1\", \"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "420dac69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_active=True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    # gt=0:id>0, ge=0:id>=0, lt=0:id<0, le=0:le<=0\n",
    "    id:int   = Field(gt=0,            description=\"id\")\n",
    "    name:str = Field(min_length=2,    description=\"name\")\n",
    "    is_active:bool=Field(default=True,description=\"id활성화\")\n",
    "user = User(id=\"1\", name=\"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e7b4458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CountryDetail"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables = [\"country\"]    \n",
    ")\n",
    "class CountryDetail(BaseModel): # description: 더 정확한 출력 유도\n",
    "    capital:str    = Field(description=\"the capital of the country\")\n",
    "    population:int = Field(description=\"the population of the country\")\n",
    "    language:str   = Field(description=\"the language of the country\")\n",
    "    currency:str   = Field(description=\"the currency of the country\")\n",
    "# 출력 형식 파서 + LLM\n",
    "structedllm = llm.with_structured_output(CountryDetail)\n",
    "\n",
    "# output_parser = JsonOutputParser()\n",
    "# output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"})))\n",
    "\n",
    "info = structedllm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "type(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c3844e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital='Seoul' population=51 language='Korean' currency='Korean won'\n",
      "Seoul 51\n"
     ]
    }
   ],
   "source": [
    "print(info)\n",
    "print(info.capital, info.population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94cf4538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 json : {\"capital\":\"Seoul\",\"population\":51,\"language\":\"Korean\",\"currency\":\"Korean won\"}\n",
      "info를 dict : {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'Korean won'}\n"
     ]
    }
   ],
   "source": [
    "print('info를 json :', info.model_dump_json()) # json()\n",
    "print('info를 dict :', info.model_dump()) # dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d6c46",
   "metadata": {},
   "source": [
    "# 4. LCEL을 활용한 렝체인 생성하기\n",
    "- invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a73bc2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model=\"llama3.2:1b\", \n",
    "                 temperature=0) # 일관된 답변\n",
    "# 명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Return the name of the city only\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960e9e03",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    "- 파이프연산자( | ) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c0ca42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> llm -> 출력파서를 연결하는 체인 생성\n",
    "capital_chain = prompt_template | llm | output_parser\n",
    "# 생성된 체인 invoke\n",
    "capital_chain.invoke({\"country\" : \"Korea\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ba8e7",
   "metadata": {},
   "source": [
    "## 3) 복합 체인 구성\n",
    "- 여러 단계의 추론이 필요한 경우(체인 연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0642078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 -> 나라명\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "country_prompt = PromptTemplate(\n",
    "    template = \"\"\"Guess the name of the country based on the following information:{information}\n",
    "    Return the name of the country only.\"\"\",\n",
    "    input_varables=[\"information\"]\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                                                      \"This country is very famous for its wine.\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea4b24bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라명 추측 체인 생성\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "# type(country_chain)\n",
    "country_chain.invoke({\"information\":\"This country is very famous for its wine.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79c9d029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 => (나라명 ->) 그 나라 수도\n",
    "final_chain = country_chain | capital_chain\n",
    "final_chain.invoke({\"information\" : \"This country is very famous for its wine.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7901b5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = {\"country\" : country_chain} | capital_chain\n",
    "final_chain.invoke({\"information\" : \"This country is very famous for its wine.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "094e301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain = {\"information\" : RunnablePassthrough()} | {\"country\" : country_chain} | capital_chain\n",
    "final_chain.invoke(\"This country is very famous for its wine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f3b316b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿에 변수 2\n",
    "# 나라 설명 -> 나라명\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "country_prompt = PromptTemplate(\n",
    "    template = \"\"\"Guess the name of the country in the {continent} based\n",
    "    on the following information:\n",
    "    {information}\n",
    "    Return the name of the country only.\"\"\",\n",
    "    input_varables=[\"information\", \"continent\"]\n",
    ")\n",
    "# output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "#                                                       \"This country is very famous for its wine.\",\n",
    "#                                                                         \"continent\":\"Europe\"})))\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "country_chain.invoke({\"information\" : \"This country is very famous for its wine.\",\n",
    "                      \"continent\":\"Europe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2997fb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = {\"country\" : country_chain} | capital_chain\n",
    "final_chain.invoke({\"information\":\"This country is very famous for its wine.\",\n",
    "                     \"continent\":\"Europe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca4404b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671a6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184925e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4d4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a8d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a0588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ced56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c62a217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928b0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b14562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e3090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246.55px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
