{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8ec294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:86% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.output {font-size:15pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:15px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:86% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.output {font-size:15pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:15px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480418b5",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch2. LLM활용의 기본 개념(Ollama)</span>\n",
    "\n",
    "# 1. LLM을 활용하여 답변 생성하기\n",
    "\n",
    "## 1) Ollama 이용한 로컬 LLM 이용\n",
    "- 성능은 GPT, Claude 같은 모델보다는 떨어짐 / 개념 설명을 의해 open source 모델 사용\n",
    "\n",
    "### ⓐ ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "- ollama pull deepseek-r1:1.5b(window키 + R -> powershell 창 실행) -> ollama run deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ec3d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\n\\n</think>\\n\\nKorea, officially known as the People's Democratic Republic of China (PRD of China), is a multi-ethnic country located in South East Asia. Its government, the Party of the Korean people, consists of the Democratic Progressive Army and various independent political parties from different ethnic groups. The capital of Korea is首尔 (Pusan), which is also the administrative capital of South Korea.\", additional_kwargs={}, response_metadata={'model': 'deepseek-r1:1.5b', 'created_at': '2025-06-25T02:12:23.3854531Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4736457800, 'load_duration': 21742600, 'prompt_eval_count': 10, 'prompt_eval_duration': 243747800, 'eval_count': 83, 'eval_duration': 4470137700, 'model_name': 'deepseek-r1:1.5b'}, id='run--7373f2ba-64e9-48a0-8e4b-d8bb88601519-0', usage_metadata={'input_tokens': 10, 'output_tokens': 83, 'total_tokens': 93})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result # 추론모델<think>~<think>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe25235",
   "metadata": {},
   "source": [
    "### ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "- ollama pull llama3.2:1b -> ollama run llama3.2:1b\n",
    "- llama : 공식적으로 한글지원 안됨(llama3.1:405b 한글지원 가능->llama3.3:70b)\n",
    "- exaone : 공식적으로 한글 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d85ebce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of South Korea is Seoul. However, the official administrative divisions are divided into nine special cities and two provinces.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T02:20:25.0552031Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3468262800, 'load_duration': 1412342200, 'prompt_eval_count': 32, 'prompt_eval_duration': 603693400, 'eval_count': 25, 'eval_duration': 1451283500, 'model_name': 'llama3.2:1b'}, id='run--fde1afe4-7cc7-4091-8d8e-c3bc4fd0c5bd-0', usage_metadata={'input_tokens': 32, 'output_tokens': 25, 'total_tokens': 57})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "773eb3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of South Korea is Seoul. However, the official administrative divisions are divided into nine special cities and two provinces.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebe1517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국의 수도는 Seoul입니다.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T02:20:48.0236316Z', 'done': True, 'done_reason': 'stop', 'total_duration': 703985900, 'load_duration': 26690200, 'prompt_eval_count': 32, 'prompt_eval_duration': 250202200, 'eval_count': 8, 'eval_duration': 426858400, 'model_name': 'llama3.2:1b'}, id='run--dbde3a36-407c-4a67-8439-4224b8607b81-0', usage_metadata={'input_tokens': 32, 'output_tokens': 8, 'total_tokens': 40})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"한국 수도는 어디예요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92df044",
   "metadata": {},
   "source": [
    "## 2) Openai 활용\n",
    "- pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6f4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# result = llm.invoke(\"What is the capital of Korea?\")\n",
    "# result - 에러 이유 : 환경변수(OPENAI_API_KEY) 부재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06d15c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경 변수 가져오기\n",
    "from dotenv import load_dotenv\n",
    "# import os\n",
    "load_dotenv()\n",
    "# os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f810bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩에서 OPENAI_API_KEY 읽어오기(.env 못씀)\n",
    "# 보안키 추가 후\n",
    "# from google.colab import userdata\n",
    "# userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f36a193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국의 수도는 서울입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 19, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_f12167b370', 'id': 'chatcmpl-BmBeTsswM5lsdljbfdwrCrvC1YcwQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e40df399-4acf-4ec0-95b6-15397dafe782-0', usage_metadata={'input_tokens': 19, 'output_tokens': 7, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\",\n",
    "#                  openai_api_key=os.genenv('OPENAI_API_KEY'),\n",
    "                )\n",
    "llm.invoke(\"What is the capital of Korea? Answer me in Korean.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8a1e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델의 키가 OPENAI_API_KEY는 아님\n",
    "# Claude -> Anthropic\n",
    "# Azure, upstage, Bedrock : 에러 메세지 참조하여 환경변수 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "072d93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import AzureOpenAI\n",
    "# llm = AzureOpenAI(model=\"gpt-4.1-nano\")\n",
    "# 에러를 내면 OPENAI_API_VERSION 환경변수가 필요하다는 메세지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7501334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "# llm.invoke(\"What is the capital of Korea?\")\n",
    "# 에러 메세지를 봐도 환경변수 이름을 알 수 없음(claude만 해당) -> ChatAnthropic을 google에 검색 후 langchain docs에서 명시한\n",
    "# ANTHROPIC_API_KEY 이름의 환경 변수 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835eb554",
   "metadata": {},
   "source": [
    "# 2. 렝체인 스타일로 프롬프트 작성하기\n",
    "- 프롬프트 : llm호출시 쓰는 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e11ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "# llm.invoke(0)\n",
    "# 프롬프트 타입 : 스트링, PromptValue, BaseMessage리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2396b",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    "- PromptTemplate을 사용하여 변수가 포함된 템플릿 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c5dacc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of South Korea is Seoul. However, in 1989, North Korea and South Korea declared their separation from each other, and Pyongyang (the capital of North Korea) became a de facto separate country. Today, both countries are independent nations with their own governments and international recognition.\\n\\nThat being said, the Republic of Korea (South Korea) is an internationally recognized sovereign state, and Seoul remains its capital to this day.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T05:31:48.7599575Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5164806700, 'load_duration': 22681300, 'prompt_eval_count': 31, 'prompt_eval_duration': 62673900, 'eval_count': 87, 'eval_duration': 5079438000, 'model_name': 'llama3.2:1b'}, id='run--2f14c9cf-239f-4aaa-ba3f-01e99fe36b39-0', usage_metadata={'input_tokens': 31, 'output_tokens': 87, 'total_tokens': 118})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}\", # {}안의 값을 새로운 값으로 대입 가능\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "prompt = prompt_template.invoke({\"country\":\"Korea\"})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae37d3a",
   "metadata": {},
   "source": [
    "## 2) 메세지 기반 프롬프트 작성\n",
    "- BaseMessage리스트\n",
    "- BaseMessage 상속받은 클래스 : AIMessage, HumanMessage, SystemMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bd6aef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T05:51:09.9288942Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3158434600, 'load_duration': 1387714800, 'prompt_eval_count': 86, 'prompt_eval_duration': 1350033900, 'eval_count': 8, 'eval_duration': 417939300, 'model_name': 'llama3.2:1b'}, id='run--bdd85fb7-14b3-4984-bc06-206ef98e323b-0', usage_metadata={'input_tokens': 86, 'output_tokens': 8, 'total_tokens': 94})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"),\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"),\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),\n",
    "    HumanMessage(content=\"What is the capital of Korea?\"),\n",
    "    AIMessage(content=\"The capital of Korea is Seoul.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\")\n",
    "]\n",
    "llm.invoke(message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7321e0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Italy?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of Italy is Rome.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of Korea?', additional_kwargs={}, response_metadata={}), AIMessage(content='The capital of Korea is Seoul.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# BaseMessage list로 하면 렝체인화X, ChatPromptTemplate X\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"),\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"),\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),\n",
    "    HumanMessage(content=\"What is the capital of Korea?\"),\n",
    "    AIMessage(content=\"The capital of Korea is Seoul.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\")\n",
    "]\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chatPromptTemplate = ChatPromptTemplate.from_messages(message_list)\n",
    "prompt = chatPromptTemplate.invoke({'country':'Korea'})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24912a",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate 사용\n",
    "- BaseMessage 리스트 -> 튜플 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3778fac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요?중국\n",
      "프롬프트 :  messages=[SystemMessage(content='You are a helpful assistant!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of 중국?', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of China is Beijing.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 BaseMessage를 수정\n",
    "chatPromptTemplate = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant!\"),\n",
    "    (\"human\", \"What is the capital of {country}?\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요?\")\n",
    "prompt = chatPromptTemplate.invoke({'country':country})\n",
    "print(\"프롬프트 : \",prompt)\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3aeabe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요?한국\n",
      "프롬프트 :  messages=[SystemMessage(content='당신은 대한민국 전문 도우미야!', additional_kwargs={}, response_metadata={}), HumanMessage(content='한국의 수도가 어디예요?', additional_kwargs={}, response_metadata={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' 대한민국의 수도는 Seoul입니다.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T06:25:29.2932556Z', 'done': True, 'done_reason': 'stop', 'total_duration': 526291500, 'load_duration': 28666000, 'prompt_eval_count': 43, 'prompt_eval_duration': 64631500, 'eval_count': 8, 'eval_duration': 431602200, 'model_name': 'llama3.2:1b'}, id='run--194f186f-1e17-4f5a-ac6d-60453130e4ed-0', usage_metadata={'input_tokens': 43, 'output_tokens': 8, 'total_tokens': 51})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatPromptTemplate = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 대한민국 전문 도우미야!\"),\n",
    "    (\"human\", \"{country}의 수도가 어디예요?\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요?\")\n",
    "prompt = chatPromptTemplate.invoke({'country':country})\n",
    "print(\"프롬프트 : \",prompt)\n",
    "result = llm.invoke(prompt)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9a52d",
   "metadata": {},
   "source": [
    "# 3. 답변 형식을 컨트롤하기\n",
    "- invoke 실행결과는 AIMessage() -> String이나 json, 객체 : outputParser 이용\n",
    "\n",
    "## 1) 문자열 출력 파서 이용\n",
    "- StrOutputParser를 사용하여 LLM 출력(AIMessage)을 단순 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "563cf5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프롬프트 :  text='What is the capital of Korea. Return the name of the city only'\n",
      "llm 결과 :  <class 'langchain_core.messages.ai.AIMessage'> content='Seoul' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T06:40:11.8143241Z', 'done': True, 'done_reason': 'stop', 'total_duration': 228050500, 'load_duration': 27742500, 'prompt_eval_count': 39, 'prompt_eval_duration': 76571800, 'eval_count': 3, 'eval_duration': 123676200, 'model_name': 'llama3.2:1b'} id='run--2678d6fc-73b0-42c9-a722-da7e6ebe3b95-0' usage_metadata={'input_tokens': 39, 'output_tokens': 3, 'total_tokens': 42}\n",
      "파서 결과 :  Seoul\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Return the name of the city only\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "# 프롬프트 템플릿에 값 주입\n",
    "prompt = prompt_template.invoke({\"country\" : \"Korea\"})\n",
    "print(\"프롬프트 : \",prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print(\"llm 결과 : \", type(result), result)\n",
    "# 문자열 출력 파서를 이용하여 llm응답을 단순 문자열 변환\n",
    "output_parser = StrOutputParser()\n",
    "print('파서 결과 : ', output_parser.invoke(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04df4b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9489969d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate(변수설정) => ChatPromptTemplate(변수설정, system과 모범답안 지정)\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant with expertise in South Korea.\"),\n",
    "    (\"human\", \"What is the capital of {country}? Return the name if the city only.\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(chat_prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592cce1a",
   "metadata": {},
   "source": [
    "## 2) Json 출력 파서 이용\n",
    "- json()으로 응답하기를 원하지만, 우선 어떤 형식으로 반환되는지 확인\n",
    "- {\"name\":\"홍\", \"age\":22}(json) / {\"name\":\"홍\", \"age\":22}(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2b9323e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.StringPromptValue'> text='Give following information about Korea\\n    - Capital\\n    - Population\\n    - Language\\n    - Currency\\n    return it is JSON format and return the JSON dictionary only'\n",
      "<class 'langchain_core.prompt_values.StringPromptValue'> content='```\\n{\\n    \"capital\": \"Seoul\",\\n    \"population\": 51000000,\\n    \"language\": \"Korean\",\\n    \"currency\": \"South Korean won\"\\n}\\n```' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-06-25T07:50:21.7437066Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5411427100, 'load_duration': 1687082000, 'prompt_eval_count': 59, 'prompt_eval_duration': 1158716200, 'eval_count': 40, 'eval_duration': 2564497200, 'model_name': 'llama3.2:1b'} id='run--4e67f0ad-eee1-4301-b963-c90e879d9233-0' usage_metadata={'input_tokens': 59, 'output_tokens': 40, 'total_tokens': 99}\n",
      "<class 'dict'> {'capital': 'Seoul', 'population': 51000000, 'language': 'Korean', 'currency': 'South Korean won'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables = [\"country\"]    \n",
    ")\n",
    "prompt = country_detail_prompt.invoke({\"country\":\"Korea\"})\n",
    "print(type(prompt), prompt)\n",
    "# Json output 파서\n",
    "output_parser = JsonOutputParser()\n",
    "ai_message = llm.invoke(prompt)\n",
    "print(type(prompt), ai_message)\n",
    "json_result = output_parser.invoke(ai_message)\n",
    "print(type(json_result), json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7c5f610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Seoul',\n",
       " 'population': 51000000,\n",
       " 'language': 'Korean',\n",
       " 'currency': 'KRW'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables = [\"country\"]    \n",
    ")\n",
    "output_parser = JsonOutputParser()\n",
    "info = output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\n",
    "                                                                     \"Korea\"})))\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43509438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe226b69",
   "metadata": {},
   "source": [
    "## 3) 구조화된 출력 사용\n",
    "- Pydantic 모델을 사용하여 LLM 출력을 구조화된 형식으로 받기(JsonParser보다 훨씬 안정적)\n",
    "- Pydantic : 데이터 유효성 검사, 설정관리를 간편하게 해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8e8e509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x00000209DCDE69E0>\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self, id, name, is_active=True):\n",
    "        self.id = id\n",
    "        self.name = name\n",
    "        self.is_active = is_active\n",
    "user = User(\"1\", \"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "420dac69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_active=True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    # gt=0:id>0, ge=0:id>=0, lt=0:id<0, le=0:le<=0\n",
    "    id:int   = Field(gt=0,            description=\"id\")\n",
    "    name:str = Field(min_length=2,    description=\"name\")\n",
    "    is_active:bool=Field(default=True,description=\"id활성화\")\n",
    "user = User(id=\"1\", name=\"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e7b4458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CountryDetail"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it is JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables = [\"country\"]    \n",
    ")\n",
    "class CountryDetail(BaseModel): # description: 더 정확한 출력 유도\n",
    "    capital:str    = Field(description=\"the capital of the country\")\n",
    "    population:int = Field(description=\"the population of the country\")\n",
    "    language:str   = Field(description=\"the language of the country\")\n",
    "    currency:str   = Field(description=\"the currency of the country\")\n",
    "# 출력 형식 파서 + LLM\n",
    "structedllm = llm.with_structured_output(CountryDetail)\n",
    "\n",
    "# output_parser = JsonOutputParser()\n",
    "# output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"})))\n",
    "\n",
    "info = structedllm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "type(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c3844e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital='Seoul' population=51 language='Korean' currency='South Korean won'\n",
      "Seoul 51\n"
     ]
    }
   ],
   "source": [
    "print(info)\n",
    "print(info.capital, info.population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94cf4538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 json : {\"capital\":\"Seoul\",\"population\":51,\"language\":\"Korean\",\"currency\":\"South Korean won\"}\n",
      "info를 dict : {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'South Korean won'}\n"
     ]
    }
   ],
   "source": [
    "print('info를 json :', info.model_dump_json()) # json()\n",
    "print('info를 dict :', info.model_dump()) # dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d6c46",
   "metadata": {},
   "source": [
    "# 4. LCEL을 활용한 렝체인 생성하기\n",
    "- invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a73bc2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model=\"llama3.2:1b\", \n",
    "                 temperature=0) # 일관된 답변\n",
    "# 명시적인 지시사항이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Return the name of the city only\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960e9e03",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    "- 파이프연산자( | ) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c0ca42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> llm -> 출력파서를 연결하는 체인 생성\n",
    "capital_chain = prompt_template | llm | output_parser\n",
    "# 생성된 체인 invoke\n",
    "capital_chain.invoke({\"country\" : \"Korea\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0642078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b24bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9d029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901b5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246.55px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
